% Note that depending on your settings in the table of contents, subsections and subsubsections might appear virtually identical.
% Make sure to set the ToC depth and the numbering depth in the ToC the way you want.
\chapter{Conclusion}\label{ch:conclusion}

In this thesis, we have addressed the complex challenge of modeling neural dynamics and their relationship with behavior. Through this process, we have developed new scalable methods specifically designed for analyzing neural data. This development is informed by the limitations and capabilities of existing machine learning techniques, including LFADS, NDT, and POYO, which have been instrumental in advancing our understanding of neural dynamics.
\\

The core contribution of our work is the introduction of a novel class of autoregressive models. These models are designed to effectively manage the high temporal resolution characteristic of neural spiking data, a challenge that traditional transformer-based models have struggled with, particularly in high-frequency contexts. Our proposed models showcase an enhanced capability to capture long-range dependencies in time series data. Moreover, they exhibit improved computational efficiency, a crucial advantage considering the complexity and scale of neural datasets.
\\

Importantly, while our methods are developed with a focus on neural data, we recognize their potential applicability in other areas that involve sequence modeling, such as language processing, finance, and engineering. This adaptability underlines the broader relevance of our approach.
\\

In summary, this thesis contributes to the field of neuroscience by providing new tools and perspectives for understanding brain dynamics and behavior. The methodologies we have developed, while tailored for neural data, hold promise for broader applications in various sequence modeling tasks, highlighting the potential for cross-disciplinary impact.