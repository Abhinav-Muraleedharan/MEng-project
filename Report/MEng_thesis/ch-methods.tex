\chapter{Methods}
\section{Problem Statement}

This is a text citation~\cite{Knight2021}. Prediction & Transduction. 
Imagine we are recording data from $D$ neurons distributed across different regions of the brain. Let $x(t_i) \in \mathbb{R}^D$ denote the observed neural activity at timestep $t_i$ and let $y_i$ denote the observed behaviour of the animal at timestep $t_i$. From the time series dataset $\mathcal{D} = \{(x_i,y_i,t_i) \}_{i=1}^N$ of neural recordings, our goal is to
construct:
\begin{itemize}
    \item A predictive model of underlying brain dynamics
    \item A probabilistic model to predict behaviour of the organism at time $t+1$ given brain recordings until timestep $t$.
\end{itemize}
More formally, let's assume that the spiking activity is generated by an underlying non-stationary stochastic process defined by $p_t(x)$. 
\begin{equation}
    x(t) \sim p_t(x)
\end{equation}
The probability of observing a sequence of neural recordings and behavior can be expressed as:
\begin{equation}
    p( \{x_1,y_1\},\{x_2,y_2\},\{x_3,y_3\},..) = 
    \lim_{N \to \infty} \prod_{i=1}^{N} p(\{x_{i},y_{i}\}| \{x_1,y_1\},\{x_2,y_2\},..\{x_{i-1},y_{i-1}\})
\end{equation}
In the context of neural recordings, it is convenient to assume that the neural recording data and behavior can be modelled with separate probability distributions of the form:
\begin{equation}
   \prod_{i=1}^{N} p_d(\{x_{i}\}| \{x_1\},\{x_2\},..\{x_{i-1}\})
\end{equation}
\begin{equation}
   \prod_{i=1}^{N} p_b(\{y_{i}\}| \{x_1\},\{x_2\},..\{x_{i-1}\})
\end{equation}
Specifically, we assume that that the neural observed neural spiking data at timestep $t_i$ is not dependent on the behavior variables in the preceding timesteps. Probability distributions of this nature have been extensively investigated in the field of language modeling. In conventional autoregressive frameworks, the approximation of conditional distributions often involves the utilization of parameterized models constrained by a finite context limit \cite{vaswani2017attention}. While autoregressive models of this kind have been extremely successful in generating plausible language \cite{radford2018improving}, they still struggle to capture long-range dependencies due to the finite context length limit\cite{hahn2020theoretical}. Furthermore, the complexity of training and inference of transformer-based models is $\mathcal{O}(N^2)$, where $N$ is the context length of the transformer model.\\




\section{Theory}

\subsection{Retention}
Mathematically, retention is defined as an exponentially weighted sum of a sequence of discrete vectors. If the vectors are drawn from a continuous space, then we perform thresholding operation to discretize the vectors. 
Specifically, given a sequence of vectors $\{x_i\}_{i=1}^N$, $x_i \in \mathbb{R}^d$ , Retention variable $ \zeta_k $ as:
\begin{equation}
    \zeta_i = \sum_{k=1}^{i-1} 2^{-k} \sigma_{\theta}(x_{i-k}) 
\end{equation}
Here, $x_k \in \mathbb{R}^D$ is the observed neural activity at timestep $t_k$, and $\sigma_{\theta}: \mathbb{R}^D \rightarrow \{0,1,2,,M\}^D $ is a thresholding function, where $\sigma_{\theta}(x_i^{j}) = 1, \forall x_i^{j} > \theta $. (We use the notation $x_i^{j}$ to denote $j$ th element of the vector $x_i$.)
\\

Now, note that $\zeta_k $ has a recursive property, specifically:
\begin{equation}
    \zeta_{i+1} = 2^{-1}\zeta_i +  2^{-1}\sigma_{\theta}(x_i)
\end{equation}
\subsection{Modelling Conditional Distributions with Retention Variables}
Now, we approximate the conditional distribution defined in eq(3) with 
\begin{equation}
   \prod_{i=1}^{N} p_d(\{x_{i}\}| \{x_1\},\{x_2\},..\{x_{i-1}\}) 
   \approx  \prod_{i=1}^{N} p_d(\{x_{i}\}|\zeta_i)
\end{equation}
To learn the dynamics of the brain from neural recordings in an unsupervised manner, we maximize the following likelihood:
\begin{equation}
    \mathcal{L}(X,\theta) = \sum_i log(p_d(\{x_{i}\}|\zeta_i;\theta))
\end{equation}
Here, $X = \{x_1,x_2,....x_M\}$, the dataset of neural recordings. \\

Note that in this approach, the context window is not bounded, and the complexity of learning the parametrized model $p_d(\{x_{i}\}|\zeta_i;\theta)$ is independent of the length of the context window. While training the model, we apply eq(6) to recursively update $\zeta_i$ in an online fashion, instead of pre-computing and storing $\{\zeta_i\}_{i=1}^N$ separately.
 \\

 To learn the correlation between neural dynamics and behavior, we follow a similar approach and approximate the conditional distribution defined in eq(4) with:
\\
 \begin{equation}
   \prod_{i=1}^{N} p_b(\{y_{i}\}| \{x_1\},\{x_2\},..\{x_{i-1}\}) 
   \approx  \prod_{i=1}^{N} p_b(\{y_{i}\}|\zeta_i)
\end{equation}
We define the loss function associated with this approach as the negative log-likelihood of the observed behavioral outcomes given the estimated neural activity states. Formally, the loss function \( \mathcal{L} \) is expressed as:

\[
\mathcal{L}(X,Y,\phi) = -\sum_{i} \log p_b(\{y_i\}|\zeta_i;\phi)
\]



\section{Model Architecture}
\section{Data}
\section{Training}

\lipsum[12]
\begin{table}
  \centering
  \caption{The quick brown fox}
  \input{tab/quick}
\end{table}
\lipsum[13]
\subsection{Data Collection}
\lipsum[16]
\section{Model}
\section{Conclusion}
\lipsum[20]
\begin{equation}
  y = mx + b
\end{equation}
\lipsum[22-25]